{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification task\n",
    "\n",
    "This notebook covers the stages of building the classifier model. These will include:\n",
    "- Original vs enhanced in a general comparison\n",
    "- Selection comparsion\n",
    "- Hyperparameter tuning\n",
    "- Final training\n",
    "\n",
    "The following libraries are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:18.284709Z",
     "start_time": "2019-05-14T19:01:18.279705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras_metrics\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import load_model\n",
    "\n",
    "# Pretrained architectures\n",
    "from keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:10:12.171144Z",
     "start_time": "2019-05-14T18:10:12.163165Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer freezing without batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:10:13.028617Z",
     "start_time": "2019-05-14T18:10:13.025615Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_norm_unfrozen(model):\n",
    "    for layer in model.layers[:-4]:    \n",
    "        if str(layer.__class__)[-20:-2] != 'BatchNormalization':  # Keep Batch normalization layers trainable\n",
    "            layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define top layer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:10:13.462206Z",
     "start_time": "2019-05-14T18:10:13.457218Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_top(base_model, dense=256, active='relu', dropout=0.5):\n",
    "    base_out = base_model.output\n",
    "    base_out = GlobalAveragePooling2D()(base_out)\n",
    "    base_out = Dense(dense, activation=active)(base_out)\n",
    "    base_out = Dropout(dropout)(base_out)\n",
    "    base_out = Dense(1, activation='sigmoid')(base_out)\n",
    "\n",
    "    return Model(base_model.input, base_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:10:14.117917Z",
     "start_time": "2019-05-14T18:10:14.113956Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_tensorboard(name, directory='logs/cls/'):\n",
    "    return TensorBoard(log_dir=directory + str(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:10:14.581849Z",
     "start_time": "2019-05-14T18:10:14.577860Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_early_stop(patience=50, verbose=0):\n",
    "    return EarlyStopping(monitor='val_loss', \n",
    "                         patience=patience,\n",
    "                         mode='min',\n",
    "                         verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:10:15.060338Z",
     "start_time": "2019-05-14T18:10:15.057345Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_lr_plateau(factor=0.5, patience=25, verbose=0):\n",
    "    return ReduceLROnPlateau(monitor='val_loss', \n",
    "                             factor=factor, \n",
    "                             patience=patience, \n",
    "                             mode='min',\n",
    "                             verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:00:03.657880Z",
     "start_time": "2019-05-14T19:00:03.653917Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_retained(y_true, y_pred):\n",
    "    true_pos = np.sum([pred and true for true, pred in zip(y_true, y_pred)])\n",
    "    true_neg = np.sum([not pred and not true for true, pred in zip(y_true, y_pred)])\n",
    "    false_pos = np.sum([pred > true for true, pred in zip(y_true, y_pred)])\n",
    "    \n",
    "    return (true_pos + true_neg + false_pos*0.64)/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:13:57.345465Z",
     "start_time": "2019-05-14T16:13:57.341467Z"
    }
   },
   "source": [
    "Define batch and image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:35.707660Z",
     "start_time": "2019-05-14T19:01:35.703671Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "IMAGE_SHAPE = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image data generator for full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:36.249369Z",
     "start_time": "2019-05-14T19:01:36.246407Z"
    }
   },
   "outputs": [],
   "source": [
    "full_train_datagen = ImageDataGenerator(rotation_range=90, \n",
    "                                   shear_range=0.3, \n",
    "                                   zoom_range=0.3, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True, \n",
    "                                   rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image data generator for validation sets\n",
    "\n",
    "Define augmentations and validation set of image data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:36.729452Z",
     "start_time": "2019-05-14T19:01:36.726461Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=90, \n",
    "                                   shear_range=0.3, \n",
    "                                   zoom_range=0.3, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True, \n",
    "                                   rescale=1./255,\n",
    "                                   validation_split=0.197)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image data generator for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:37.226355Z",
     "start_time": "2019-05-14T19:01:37.222366Z"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataframes\n",
    "\n",
    "Drop percentage for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:38.022578Z",
     "start_time": "2019-05-14T19:01:37.974122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validation sets for model comparisons\n",
    "df_train = []\n",
    "for idx in range(10):\n",
    "    df_train.append(pd.read_csv('dataframes/train_'+ str(idx) + '.csv').drop(['percentage'], axis=1))\n",
    "\n",
    "# Full training set for final model training\n",
    "full_df_train = pd.read_csv('dataframes/train.csv').drop(['percentage'], axis=1)\n",
    "   \n",
    "# Test set for final evaluation\n",
    "df_test = pd.read_csv('dataframes/test.csv').drop(['percentage'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data generators for the original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:01:38.819551Z",
     "start_time": "2019-05-14T19:01:38.486656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 650 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 810 images belonging to 2 classes.\n",
      "Found 200 images.\n"
     ]
    }
   ],
   "source": [
    "# Validation set generators\n",
    "train_gen = []\n",
    "valid_gen = []\n",
    "\n",
    "for idx in range(10):\n",
    "    train_gen.append(train_datagen.flow_from_dataframe(\n",
    "                        dataframe=df_train[idx],\n",
    "                        directory='data/crop', \n",
    "                        x_col='filename', \n",
    "                        y_col='rbr', \n",
    "                        has_ext=True, \n",
    "                        target_size=IMAGE_SHAPE[:2], \n",
    "                        color_mode='rgb', \n",
    "                        classes=None, \n",
    "                        class_mode='binary', \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        seed=42, \n",
    "                        subset='training')\n",
    "                    )\n",
    "\n",
    "    valid_gen.append(train_datagen.flow_from_dataframe(\n",
    "                        dataframe=df_train[idx], \n",
    "                        directory='data/crop', \n",
    "                        x_col='filename', \n",
    "                        y_col='rbr', \n",
    "                        has_ext=True, \n",
    "                        target_size=IMAGE_SHAPE[:2], \n",
    "                        color_mode='rgb', \n",
    "                        classes=None, \n",
    "                        class_mode='binary', \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        seed=42, \n",
    "                        subset='validation')\n",
    "                    )\n",
    "\n",
    "# Full training set generator\n",
    "full_train_gen = full_train_datagen.flow_from_dataframe(\n",
    "                        dataframe=full_df_train,\n",
    "                        directory='data/crop', \n",
    "                        x_col='filename', \n",
    "                        y_col='rbr', \n",
    "                        has_ext=True, \n",
    "                        target_size=IMAGE_SHAPE[:2], \n",
    "                        color_mode='rgb', \n",
    "                        classes=None, \n",
    "                        class_mode='binary', \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        seed=42)\n",
    "\n",
    "# Test set generator\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "                        dataframe=df_test,\n",
    "                        directory='data/crop', \n",
    "                        x_col='filename', \n",
    "                        y_col='rbr', \n",
    "                        has_ext=True, \n",
    "                        target_size=IMAGE_SHAPE[:2], \n",
    "                        color_mode='rgb', \n",
    "                        classes=None, \n",
    "                        class_mode=None, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False, \n",
    "                        seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data generators for the equalised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T15:56:17.256113Z",
     "start_time": "2019-05-14T15:56:16.964867Z"
    }
   },
   "outputs": [],
   "source": [
    "equ_train_gen = []\n",
    "equ_valid_gen = []\n",
    "\n",
    "for idx in range(10):\n",
    "    equ_train_gen.append(train_datagen.flow_from_dataframe(\n",
    "                            dataframe=df_train[idx],\n",
    "                            directory='data/equ_crop', \n",
    "                            x_col='filename', \n",
    "                            y_col='rbr', \n",
    "                            has_ext=True, \n",
    "                            target_size=IMAGE_SHAPE[:2], \n",
    "                            color_mode='rgb', \n",
    "                            classes=None, \n",
    "                            class_mode='binary', \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, \n",
    "                            seed=42, \n",
    "                            subset='training')\n",
    "                        )\n",
    "\n",
    "    equ_valid_gen.append(train_datagen.flow_from_dataframe(dataframe=df_train[idx], \n",
    "                            directory='data/equ_crop', \n",
    "                            x_col='filename', \n",
    "                            y_col='rbr', \n",
    "                            has_ext=True, \n",
    "                            target_size=IMAGE_SHAPE[:2], \n",
    "                            color_mode='rgb', \n",
    "                            classes=None, \n",
    "                            class_mode='binary', \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, \n",
    "                            seed=42, \n",
    "                            subset='validation')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original vs enhanced images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:16:00.162460Z",
     "start_time": "2019-05-14T16:16:00.158490Z"
    }
   },
   "outputs": [],
   "source": [
    "comp_pretrained = [DenseNet121,\n",
    "                   DenseNet169,\n",
    "                   DenseNet201,\n",
    "                   InceptionResNetV2,\n",
    "                   InceptionV3,\n",
    "                   MobileNet,\n",
    "                   MobileNetV2,\n",
    "                   NASNetMobile,\n",
    "                   NASNetLarge,\n",
    "                   ResNet50,\n",
    "                   VGG16,\n",
    "                   VGG19,\n",
    "                   Xception]\n",
    "\n",
    "models = ['DenseNet121',\n",
    "          'DenseNet169',\n",
    "          'DenseNet201',\n",
    "          'InceptionResNetV2',\n",
    "          'InceptionV3',\n",
    "          'MobileNet',\n",
    "          'MobileNetV2',\n",
    "          'NASNetMobile',\n",
    "          'NASNetLarge',\n",
    "          'ResNet50',\n",
    "          'VGG16',\n",
    "          'VGG19',\n",
    "          'Xception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:16:01.510082Z",
     "start_time": "2019-05-14T16:16:01.503134Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_original(architectures, start_model, start_fold, n_folds):\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for idx, architecture in enumerate(architectures):\n",
    "        if idx >= start_model:\n",
    "            for fold in range(start_fold, 10):\n",
    "                base_model = architecture(weights='imagenet', \n",
    "                                          include_top=False, \n",
    "                                          input_shape=IMAGE_SHAPE)\n",
    "\n",
    "                model_name = models[idx]\n",
    "\n",
    "                batch_norm_unfrozen(base_model)\n",
    "                model = add_top(base_model)\n",
    "\n",
    "                model.compile( \n",
    "                    loss='binary_crossentropy', \n",
    "                    optimizer=optimizers.nadam(), \n",
    "                    metrics=[keras_metrics.precision(), keras_metrics.recall()]\n",
    "                )\n",
    "\n",
    "                train_gen[fold].reset()\n",
    "                valid_gen[fold].reset()\n",
    "\n",
    "                STEP_SIZE_TRAIN=train_gen[fold].n//train_gen[fold].batch_size\n",
    "                STEP_SIZE_VALID=valid_gen[fold].n//valid_gen[fold].batch_size\n",
    "\n",
    "                history = (model.fit_generator(generator=train_gen[fold],\n",
    "                                                steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                                validation_data=valid_gen[fold],\n",
    "                                                validation_steps=STEP_SIZE_VALID,\n",
    "                                                epochs=100,\n",
    "                                                verbose=0,\n",
    "                                                callbacks=[set_tensorboard('comp/' + model_name + '_' + str(fold))]))\n",
    "                del model\n",
    "                del base_model\n",
    "\n",
    "                if n_folds <= count:\n",
    "                    return\n",
    "                else:\n",
    "                    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:37:37.575950Z",
     "start_time": "2019-05-14T16:37:37.569974Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_equalised(architectures, start_model, start_fold, n_folds):\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for idx, architecture in enumerate(architectures):\n",
    "        if idx >= start_model:\n",
    "            for fold in range(start_fold, 10):\n",
    "                base_model = architecture(weights='imagenet', \n",
    "                                          include_top=False, \n",
    "                                          input_shape=IMAGE_SHAPE)\n",
    "\n",
    "                model_name = models[idx]\n",
    "\n",
    "                batch_norm_unfrozen(base_model)\n",
    "                model = add_top(base_model)\n",
    "\n",
    "                model.compile( \n",
    "                    loss='binary_crossentropy', \n",
    "                    optimizer=optimizers.nadam(), \n",
    "                    metrics=[keras_metrics.precision(), keras_metrics.recall()]\n",
    "                )\n",
    "\n",
    "                equ_train_gen[fold].reset()\n",
    "                equ_valid_gen[fold].reset()\n",
    "\n",
    "                STEP_SIZE_TRAIN=equ_train_gen[fold].n//equ_train_gen[fold].batch_size\n",
    "                STEP_SIZE_VALID=equ_valid_gen[fold].n//equ_valid_gen[fold].batch_size\n",
    "\n",
    "                history = (model.fit_generator(generator=equ_train_gen[fold],\n",
    "                                                steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                                validation_data=equ_valid_gen[fold],\n",
    "                                                validation_steps=STEP_SIZE_VALID,\n",
    "                                                epochs=100,\n",
    "                                                verbose=0,\n",
    "                                                callbacks=[set_tensorboard('enchanced/' + model_name + '_' + str(fold))]))\n",
    "                del model\n",
    "                del base_model\n",
    "\n",
    "                if n_folds <= count:\n",
    "                    return\n",
    "                else:\n",
    "                    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions above iterate through the list of architecture passed. It then:\n",
    "- downloads the architecture\n",
    "- freezes the layers other than batch normalisation \n",
    "- adds the top layers\n",
    "- compiles the model\n",
    "- trains the model\n",
    "\n",
    "The function layer is very similar for all comparisons run, but not identical. The function can be passed a starting point in case of interuption. A limit to the number of iterations can also be set because there is a memory leak in the process that slows down, and eventually stops, the training process. It was found that after 6 iterations, the process slowed down exponentially. Running one of the full processes takes approximately 65 hours, depending on the available computational power (GPU enabled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:18:32.792362Z",
     "start_time": "2019-05-14T16:16:01.918601Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_original(comp_pretrained, 0, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_equalised(comp_pretrained, 0, 0, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can then be analysed using Tensorboard or downloaded to csv and imported. The results of the original and enhanced images can be compared and a subset of model can be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Selection comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:37:40.135924Z",
     "start_time": "2019-05-14T16:37:40.131934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "select_pretrained = [DenseNet121,\n",
    "                    DenseNet169,\n",
    "                    DenseNet201,\n",
    "                    MobileNet,\n",
    "                    VGG16]\n",
    "\n",
    "models = ['DenseNet121',\n",
    "        'DenseNet169',\n",
    "        'DenseNet201',\n",
    "        'MobileNet',\n",
    "        'VGG16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:39:51.561103Z",
     "start_time": "2019-05-14T16:39:51.555115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compare_selected(architectures, start_model, start_fold, n_folds):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for idx, architecture in enumerate(architectures):\n",
    "        if idx >= start_model:\n",
    "            for fold in range(start_fold, 10):\n",
    "                base_model = architecture(weights='imagenet', \n",
    "                                          include_top=False, \n",
    "                                          input_shape=IMAGE_SHAPE)\n",
    "\n",
    "                model_name = models[idx]\n",
    "\n",
    "                batch_norm_unfrozen(base_model)\n",
    "                model = add_top(base_model)\n",
    "\n",
    "                model.compile( \n",
    "                    loss='binary_crossentropy', \n",
    "                    optimizer=optimizers.nadam(), \n",
    "                    metrics=[keras_metrics.precision(), keras_metrics.recall()]\n",
    "                )\n",
    "\n",
    "                train_gen[fold].reset()\n",
    "                valid_gen[fold].reset()\n",
    "\n",
    "                STEP_SIZE_TRAIN=train_gen[fold].n//train_gen[fold].batch_size\n",
    "                STEP_SIZE_VALID=valid_gen[fold].n//valid_gen[fold].batch_size\n",
    "\n",
    "                history = (model.fit_generator(generator=train_gen[fold],\n",
    "                                                steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                                validation_data=valid_gen[fold],\n",
    "                                                validation_steps=STEP_SIZE_VALID,\n",
    "                                                epochs=300,\n",
    "                                                verbose=0,\n",
    "                                                callbacks=[set_tensorboard('select/' + model_name + '_' + str(fold)),\n",
    "                                                           set_lr_plateau(),\n",
    "                                                           set_early_stop()]))\n",
    "\n",
    "                del model\n",
    "                del base_model\n",
    "                \n",
    "                if n_folds <= count:\n",
    "                    return\n",
    "                else:\n",
    "                    count = count + 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T16:59:02.281504Z",
     "start_time": "2019-05-14T16:47:09.075302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare_selected(select_pretrained, 0, 0, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T17:21:55.642391Z",
     "start_time": "2019-05-14T17:21:55.634413Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def grid_search(dense, active, start_dense=0, start_active=0, start_fold=0, n_folds=6):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for d, units in enumerate(dense):\n",
    "        if d >= start_dense:\n",
    "            for a, func in enumerate(active):\n",
    "                if a >= start_active:\n",
    "                        for fold in range(start_fold, 10):\n",
    "                            base_model = DenseNet201(weights='imagenet',\n",
    "                                                     include_top=False,\n",
    "                                                     input_shape=IMAGE_SHAPE)\n",
    "\n",
    "                            batch_norm_unfrozen(base_model)\n",
    "                            model = add_top(base_model, dense=units, active=func)\n",
    "\n",
    "                            model.compile( \n",
    "                                loss='binary_crossentropy', \n",
    "                                optimizer=optimizers.nadam(), \n",
    "                                metrics=[keras_metrics.precision(), keras_metrics.recall()]\n",
    "                            )\n",
    "\n",
    "                            # TRAIN\n",
    "                            train_gen[fold].reset()\n",
    "                            valid_gen[fold].reset()\n",
    "\n",
    "                            STEP_SIZE_TRAIN=train_gen[fold].n//train_gen[fold].batch_size\n",
    "                            STEP_SIZE_VALID=valid_gen[fold].n//valid_gen[fold].batch_size\n",
    "                            history_pretrained = model.fit_generator(generator=train_gen[fold],\n",
    "                                                                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                                                     validation_data=valid_gen[fold],\n",
    "                                                                     validation_steps=STEP_SIZE_VALID,\n",
    "                                                                     epochs=120,\n",
    "                                                                     verbose=0,\n",
    "                                                                     callbacks=[set_tensorboard('optim/DenseNet201_' + str(units) + '_' + func + '_' + str(fold))])\n",
    "\n",
    "                            del model\n",
    "                            del base_model\n",
    "                            \n",
    "                            if n_folds <= count:\n",
    "                                return\n",
    "                            else:\n",
    "                                count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T17:21:59.221783Z",
     "start_time": "2019-05-14T17:21:56.113152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Range of dense units\n",
    "dense = [16, 64, 256, 1024]\n",
    "\n",
    "# Activation functions\n",
    "active = ['relu', 'elu']\n",
    "\n",
    "grid_search(dense, active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final training uses the validation curves to establish a optimal number of epochs to train for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T17:24:29.799879Z",
     "start_time": "2019-05-14T17:24:29.792898Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_time(start_fold):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for fold in range(start_fold, 10):\n",
    "        base_model = DenseNet201(weights='imagenet',\n",
    "                                 include_top=False,\n",
    "                                 input_shape=IMAGE_SHAPE)\n",
    "\n",
    "        batch_norm_unfrozen(base_model)\n",
    "        model = add_top(base_model, dense=32, active='elu')\n",
    "\n",
    "        model.compile( \n",
    "            loss='binary_crossentropy', \n",
    "            optimizer=optimizers.nadam(), \n",
    "            metrics=[keras_metrics.precision(), keras_metrics.recall()]\n",
    "        )\n",
    "\n",
    "        # TRAIN\n",
    "        train_gen[fold].reset()\n",
    "        valid_gen[fold].reset()\n",
    "\n",
    "        STEP_SIZE_TRAIN=train_gen[fold].n//train_gen[fold].batch_size\n",
    "        STEP_SIZE_VALID=valid_gen[fold].n//valid_gen[fold].batch_size\n",
    "        history_pretrained = model.fit_generator(generator=train_gen[fold],\n",
    "                                                 steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                                 validation_data=valid_gen[fold],\n",
    "                                                 validation_steps=STEP_SIZE_VALID,\n",
    "                                                 epochs=200,\n",
    "                                                 verbose=0,\n",
    "                                                 callbacks=[set_tensorboard('final/DenseNet201_' + str(fold))])\n",
    "\n",
    "        del model\n",
    "        del base_model\n",
    "        \n",
    "        if n_folds <= count:\n",
    "            return\n",
    "        else:\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T17:34:42.256235Z",
     "start_time": "2019-05-14T17:24:32.208816Z"
    }
   },
   "outputs": [],
   "source": [
    "training_time(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function includes a learning rate plateau callback which decreases the learning rate if the validation loss plateaus. This is a mistake. It's not possible to use when training the final model since a validation set is not used. All learning rate decreased for all 10 folds on the same epoch, so the final model was trained in stages, decreasing the learning rate between each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:12:45.029608Z",
     "start_time": "2019-05-14T18:12:45.025629Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_model(model, epochs, i_epoch, learning_rate):\n",
    "    model.compile( \n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=optimizers.nadam(lr=learning_rate), \n",
    "        metrics=[keras_metrics.precision(), keras_metrics.recall()]\n",
    "    )\n",
    "\n",
    "    full_train_gen.reset()\n",
    "\n",
    "    STEP_SIZE_TRAIN=full_train_gen.n//full_train_gen.batch_size\n",
    "    history_pretrained = model.fit_generator(generator=full_train_gen,\n",
    "                                             steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                             epochs=epochs,\n",
    "                                             initial_epoch=i_epoch,\n",
    "                                             verbose=0,\n",
    "                                             callbacks=[set_tensorboard('final/DenseNet201_final')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:50:17.953884Z",
     "start_time": "2019-05-14T18:12:45.891021Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = DenseNet201(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=IMAGE_SHAPE)\n",
    "\n",
    "batch_norm_unfrozen(base_model)\n",
    "model = add_top(base_model, dense=32, active='elu', dropout=0.4)\n",
    "\n",
    "model = final_model(model, 100, 0, 0.002)\n",
    "\n",
    "model.save('models/classification_final_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:03:31.750484Z",
     "start_time": "2019-05-14T19:01:47.494553Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('models/classification_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using the test set image data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T19:05:16.687676Z",
     "start_time": "2019-05-14T19:05:13.671349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 150ms/step\n",
      "Pretrained model recall: 1.0\n",
      "Pretrained model precision: 0.9523809523809523\n",
      "Pretrained model F1 score: 0.975609756097561\n",
      "Pretrained model value score: 0.991\n"
     ]
    }
   ],
   "source": [
    "test_gen.reset()\n",
    "\n",
    "predictions = model.predict_generator(generator=test_gen, steps=test_gen.n//BATCH_SIZE, verbose=1)\n",
    "\n",
    "y_pred = predictions > 0.5\n",
    "y_true = list(df_test['rbr'].astype(int))\n",
    "\n",
    "recall = recall_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "val = value_retained(y_true, y_pred)\n",
    "\n",
    "print('Pretrained model recall: {}'.format(recall))\n",
    "print('Pretrained model precision: {}'.format(precision))\n",
    "print('Pretrained model F1 score: {}'.format(f1))\n",
    "print('Pretrained model value score: {}'.format(val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
